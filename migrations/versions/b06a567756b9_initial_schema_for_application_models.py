"""Initial schema for application models

Revision ID: b06a567756b9
Revises:
Create Date: 2025-04-26 09:12:29.594685

"""

from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
import src.utils.type_utils


# revision identifiers, used by Alembic.
revision: str = "b06a567756b9"
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "crawlers",
        sa.Column("crawler_name", sa.String(length=100), nullable=False),
        sa.Column("module_name", sa.String(length=100), nullable=False),
        sa.Column("base_url", sa.String(length=1000), nullable=False),
        sa.Column("is_active", sa.Boolean(), server_default="1", nullable=False),
        sa.Column(
            "crawler_type", sa.String(length=100), server_default="web", nullable=False
        ),
        sa.Column("config_file_name", sa.String(length=100), nullable=False),
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column(
            "created_at",
            src.utils.type_utils.AwareDateTime(),
            server_default=sa.text("timezone('UTC', now())"),
            nullable=False,
        ),
        sa.Column("updated_at", src.utils.type_utils.AwareDateTime(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("crawler_name"),
        sa.UniqueConstraint("crawler_name", name="uq_crawler_name"),
    )
    op.create_table(
        "crawler_tasks",
        sa.Column("task_name", sa.String(length=255), nullable=False),
        sa.Column("crawler_id", sa.Integer(), nullable=False),
        sa.Column("is_auto", sa.Boolean(), nullable=False),
        sa.Column("is_active", sa.Boolean(), nullable=False),
        sa.Column("is_scheduled", sa.Boolean(), nullable=False),
        sa.Column("retry_count", sa.Integer(), nullable=False),
        sa.Column("task_args", sa.JSON(), nullable=False),
        sa.Column("notes", sa.Text(), nullable=True),
        sa.Column("last_run_at", src.utils.type_utils.AwareDateTime(), nullable=True),
        sa.Column("last_run_success", sa.Boolean(), nullable=True),
        sa.Column("last_run_message", sa.Text(), nullable=True),
        sa.Column("cron_expression", sa.VARCHAR(length=255), nullable=True),
        sa.Column(
            "scrape_phase",
            sa.Enum(
                "init",
                "link_collection",
                "content_scraping",
                "failed",
                "save_to_csv",
                "save_to_database",
                "completed",
                "cancelled",
                "unknown",
                name="scrapephase",
            ),
            nullable=False,
        ),
        sa.Column(
            "task_status",
            sa.Enum(
                "init",
                "running",
                "completed",
                "failed",
                "canceling",
                "cancelled",
                "unknown",
                name="taskstatus",
            ),
            nullable=False,
        ),
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column(
            "created_at",
            src.utils.type_utils.AwareDateTime(),
            server_default=sa.text("timezone('UTC', now())"),
            nullable=False,
        ),
        sa.Column("updated_at", src.utils.type_utils.AwareDateTime(), nullable=True),
        sa.ForeignKeyConstraint(
            ["crawler_id"],
            ["crawlers.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "articles",
        sa.Column("title", sa.String(length=500), nullable=False),
        sa.Column("summary", sa.Text(), nullable=True),
        sa.Column("content", sa.Text(), nullable=True),
        sa.Column("link", sa.String(length=1000), nullable=False),
        sa.Column("category", sa.String(length=100), nullable=True),
        sa.Column("published_at", src.utils.type_utils.AwareDateTime(), nullable=True),
        sa.Column("author", sa.String(length=100), nullable=True),
        sa.Column("source", sa.String(length=50), nullable=False),
        sa.Column("source_url", sa.String(length=1000), nullable=False),
        sa.Column("article_type", sa.String(length=20), nullable=True),
        sa.Column("tags", sa.String(length=500), nullable=True),
        sa.Column("is_ai_related", sa.Boolean(), nullable=False),
        sa.Column("is_scraped", sa.Boolean(), nullable=False),
        sa.Column(
            "scrape_status",
            sa.Enum(
                "pending",
                "link_saved",
                "partial_saved",
                "content_scraped",
                "failed",
                name="articlescrapestatus",
            ),
            nullable=False,
        ),
        sa.Column("scrape_error", sa.Text(), nullable=True),
        sa.Column(
            "last_scrape_attempt", src.utils.type_utils.AwareDateTime(), nullable=True
        ),
        sa.Column("task_id", sa.Integer(), nullable=True),
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column(
            "created_at",
            src.utils.type_utils.AwareDateTime(),
            server_default=sa.text("timezone('UTC', now())"),
            nullable=False,
        ),
        sa.Column("updated_at", src.utils.type_utils.AwareDateTime(), nullable=True),
        sa.ForeignKeyConstraint(
            ["task_id"],
            ["crawler_tasks.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("link", name="uq_article_link"),
    )
    op.create_index(op.f("ix_articles_link"), "articles", ["link"], unique=True)
    op.create_table(
        "crawler_task_history",
        sa.Column("task_id", sa.Integer(), nullable=False),
        sa.Column("start_time", src.utils.type_utils.AwareDateTime(), nullable=True),
        sa.Column("end_time", src.utils.type_utils.AwareDateTime(), nullable=True),
        sa.Column("success", sa.Boolean(), nullable=True),
        sa.Column("message", sa.Text(), nullable=True),
        sa.Column("articles_count", sa.Integer(), nullable=True),
        sa.Column(
            "task_status",
            sa.Enum(
                "init",
                "running",
                "completed",
                "failed",
                "canceling",
                "cancelled",
                "unknown",
                name="taskstatus",
            ),
            nullable=False,
        ),
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column(
            "created_at",
            src.utils.type_utils.AwareDateTime(),
            server_default=sa.text("timezone('UTC', now())"),
            nullable=False,
        ),
        sa.Column("updated_at", src.utils.type_utils.AwareDateTime(), nullable=True),
        sa.ForeignKeyConstraint(
            ["task_id"],
            ["crawler_tasks.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table("crawler_task_history")
    op.drop_index(op.f("ix_articles_link"), table_name="articles")
    op.drop_table("articles")
    op.drop_table("crawler_tasks")
    op.drop_table("crawlers")
    # ### end Alembic commands ###
